# Machine Learning Basics
<img width="836" alt="image" src="https://github.com/hannahxsh/Sth-about-ML/assets/147379741/97afdee3-de1c-46ff-868d-6a4c93c06bfb">


Main package in Python:  `sklearn` \
Function References: [Functions and classes in sklearn](https://scikit-learn.org/stable/modules/classes.html#)
## 1. Supervised Learning
Some important logics in ML.
> Gradient Descent 

Introducing loss function with the goal of minimizing loss function, step by step optimizing to find the optimal fitting parameters.
<p align="center">
<img width="477" alt="image" src="https://github.com/hannahxsh/Sth-about-ML/assets/147379741/9dd199ae-cd49-451e-9c5d-5c173bf84699">

Citing linear regression as an example, there are three ways to derive gradient descent:\
Loss Function for LR:
<p align="center">
<img width="273" alt="image" src="https://github.com/hannahxsh/Sth-about-ML/assets/147379741/723083e7-75cb-498e-8adb-e06ccef7a7ca">
  
* Batch gradient descent

* Stochastic gradient descent
* Mini-batch gradient descent


> Cross Validation 

## 1.1. Regression
* Linear Regression

